{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae3edf9-be14-45f6-a8cf-c74b2a313a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from linebot import LineBotApi, WebhookHandler\n",
    "from linebot.models import TextSendMessage   # 載入 TextSendMessage 模組\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352de678-b1d0-412b-9814-9bc9a84e2183",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_bot_api = LineBotApi(LINE_BOT_KEY)\n",
    "handler = WebhookHandler(LINE_SECRET_KEY)\n",
    "signature = request.headers['X-Line-Signature']\n",
    "handler.handle(body, signature)\n",
    "tk = json_data['events'][0]['replyToken']\n",
    "msg = json_data['events'][0]['message']['text'] + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00be5e72-affb-42a1-8a7b-e0eb9ec0e067",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'msg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ai_msg \u001b[38;5;241m=\u001b[39m \u001b[43mmsg\u001b[49m[:\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m user \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevents\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'msg' is not defined"
     ]
    }
   ],
   "source": [
    "ai_msg = msg[:1]\n",
    "user = json_data[\"events\"][0][\"source\"][\"userId\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b4db7ea-26e6-40d2-9557-aa061ac770b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = open('msg.txt','r').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074c6cde-8838-4ff6-aa5b-a266e1275ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'destination': 'U8fc2cf34709adb71eead5cd0c6b817bd', 'events': [{'type': 'message', 'message': {'type': 'text', 'id': '496375511698898945', 'quoteToken': '24R1jGuXLaJ-e6MAUvgy727dYSH3iCgkXtkQw7lKNw1WnNn5olmlOaumayp8i82u_v92w5VtiejZSA7djy3l4lhCc5grnBCHVqFiuuZn6APYxBoz6wmen4uURTWNo-Dw2jf0GCitt430-ocL4w4w4A', 'text': '/香港有什麼好吃的?'}, 'webhookEventId': '01HQB1QN4RVXEYW39XQBVCV7DQ', 'deliveryContext': {'isRedelivery': False}, 'timestamp': 1708694164509, 'source': {'type': 'group', 'groupId': 'Cfe618dad7889d938554ea9b223d3d56c', 'userId': 'Uf823a8090fbc98490efacc7f93352aa7'}, 'replyToken': '872a62002ee843539e99ba4a1cbcb5b2', 'mode': 'active'}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e02cf21-33bd-43c0-93cc-40165f38db3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'destination': 'U8fc2cf34709adb71eead5cd0c6b817bd',\n",
       " 'events': [{'type': 'message',\n",
       "   'message': {'type': 'text',\n",
       "    'id': '496375511698898945',\n",
       "    'quoteToken': '24R1jGuXLaJ-e6MAUvgy727dYSH3iCgkXtkQw7lKNw1WnNn5olmlOaumayp8i82u_v92w5VtiejZSA7djy3l4lhCc5grnBCHVqFiuuZn6APYxBoz6wmen4uURTWNo-Dw2jf0GCitt430-ocL4w4w4A',\n",
       "    'text': '/香港有什麼好吃的?'},\n",
       "   'webhookEventId': '01HQB1QN4RVXEYW39XQBVCV7DQ',\n",
       "   'deliveryContext': {'isRedelivery': False},\n",
       "   'timestamp': 1708694164509,\n",
       "   'source': {'type': 'group',\n",
       "    'groupId': 'Cfe618dad7889d938554ea9b223d3d56c',\n",
       "    'userId': 'Uf823a8090fbc98490efacc7f93352aa7'},\n",
       "   'replyToken': '872a62002ee843539e99ba4a1cbcb5b2',\n",
       "   'mode': 'active'}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "920e60f8-e719-4cd7-9157-b4522eadf236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "class Mood:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.user_id = kwargs.get(\"user_id\") if kwargs.get(\"user_id\") != None else f'{uuid.uuid4()}'\n",
    "        self.group_id = kwargs.get(\"group_id\") \n",
    "        self.user_text = kwargs.get(\"user_text\") \n",
    "        self.user_mood = kwargs.get(\"user_mood\") \n",
    "        self.mood_score = kwargs.get(\"mood_score\") \n",
    "        self.stable_score = kwargs.get(\"stable_score\") \n",
    "        self.engage = kwargs.get(\"engage\") \n",
    "        if any(value is None for value in [self.user_id, self.user_text, self.user_mood, self.mood_score, self.stable_score, self.engage]): \n",
    "            raise ValueError(\"請輸入完整的屬性\")\n",
    "            \n",
    "    def update(self, **kwargs):\n",
    "        self.group_id = kwargs.get(\"group_id\") \n",
    "        self.user_text = kwargs.get(\"user_text\") \n",
    "        self.user_mood = kwargs.get(\"user_mood\") \n",
    "        self.mood_score = kwargs.get(\"mood_score\") \n",
    "        self.stable_score = kwargs.get(\"stable_score\") \n",
    "        self.engage = kwargs.get(\"engage\")\n",
    "        if \"user_id\" in kwargs.keys():\n",
    "            raise ValueError(\"UPDATE 不用設定user_id\")\n",
    "            \n",
    "        \n",
    "        update_comm = list(kwargs.keys())\n",
    "        update_comm = \" = ?, \".join(str(x) for x in update_comm)\n",
    "        lst = list(kwargs.values())\n",
    "        lst.append(self.user_id)\n",
    "        conn = sqlite3.connect('src/db/database.db')\n",
    "        c = conn.cursor()\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            print(f\"UPDATE mood SET {update_comm} = ? WHERE user_id = ?\")\n",
    "            c.execute(f\"UPDATE mood SET {update_comm} = ? WHERE user_id = ?\", tuple(lst))\n",
    "            conn.commit()\n",
    "            print(\"Command executed successfully\")\n",
    "        except Exception as e:\n",
    "            print(\"Update Failed\")\n",
    "            print(e)\n",
    "        conn.close()\n",
    "\n",
    "    def insert(self):\n",
    "        conn = sqlite3.connect('src/db/database.db')\n",
    "        c = conn.cursor()\n",
    "        try:\n",
    "            c.execute(f\"INSERT INTO mood (user_id, group_id, user_text, user_mood, mood_score, stable_score, engage) VALUES (?, ?, ?, ?, ?, ?, ?)\",\n",
    "                          (self.user_id, self.group_id, self.user_text, self.user_mood, self.mood_score, self.stable_score, self.engage))\n",
    "            conn.commit()\n",
    "            print(\"Command executed successfully\")\n",
    "        except Exception as e:\n",
    "            print(\"Insert Failed\")\n",
    "            print(e)\n",
    "        conn.close()\n",
    "    def fetch(self):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "09c7201d-d039-4868-b7e0-e6d3af5688ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = Mood(user_id=name, user_text=\"hi\", user_mood=\"happy\", mood_score=1, stable_score=2, engage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1a983a1d-0a9a-4712-99b6-1067cf790f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE mood SET user_mood = ? WHERE user_id = ?\n",
      "Command executed successfully\n"
     ]
    }
   ],
   "source": [
    "user.update(user_mood=\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33381d6c-f85e-431c-96ce-bdc5b00d8868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "name = f'{uuid.uuid4()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d3d537fe-4a71-476b-b8e5-0622ab16dc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0efef8f2-37be-4527-a3af-7c38526297e8'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04bfb20-c163-4676-a6f8-f9339c89af31",
   "metadata": {},
   "source": [
    "## Model, prompt, parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f971992d-c024-4ec7-8bcc-a00c93699219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't ice creams ever get invited to parties?\\n\\nBecause they always melt under pressure!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97ad10-e4e8-4278-906b-7c9bb3dea627",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afa3068c-f7d0-41d6-8d74-95f3f6e4762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't ice creams ever get invited to parties?\\n\\nBecause they always bring the scoop!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 基本的prompt \n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-4-1106-preview\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88550a84-b0d8-43c8-b25d-30d37ed0c6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['role', 'style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. You are a {role}text: ```{text}```\\n')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. You are a {role}\\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dcf0180-72ca-4836-a154-18ad2125e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 根據語氣做調整\n",
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "role = \"\"\"doctor\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cbc05b6-d4b0-4064-a3f9-2fd5ddc3f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    role =role,\n",
    "                    style=customer_style, #語氣\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0b98ca2-6db6-40f9-a975-b90b06f5b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.0, model=\"gpt-4-1106-preview\")\n",
    "service_repsonse = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc24218c-f6e9-41f3-a790-110bc13eaa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm quite frustrated that the lid of my blender came off and caused the smoothie to splatter all over my kitchen walls. Additionally, the warranty does not cover the cost of cleaning my kitchen, which is disappointing. I would really appreciate your assistance at this moment, my friend.\n"
     ]
    }
   ],
   "source": [
    "print(service_repsonse.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135919f2-41be-4e86-a002-bd400907fbec",
   "metadata": {},
   "source": [
    "### Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c92c4821-35c4-47a8-9080-c277c99bfe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5d406d6-d311-4a49-bd78-28d70188393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "012c01e9-5828-4d45-b2ab-4d6d090b4961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d14aa843-58a1-4996-92b3-738bc4e0cd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0, model=\"gpt-4-1106-preview\")\n",
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ee373-fcd1-4bde-bb74-e87db0596cc7",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85c34778-194a-47f4-a3cb-69f3c7d464b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57379c7-09dd-42a3-a4ce-3a0804536ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"mood_score\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4d03afe-1625-487e-a86f-70955d3f4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49c335dc-0b4f-4fd9-ba03-705f87660999",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc1849eb-9d58-411c-9c5a-8756061c1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2165bbe6-87df-4a69-bf5e-ca14d1be006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa30bd93-fc49-4834-a860-ede4cb2bb8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": \"True\",\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67e75dc0-3d64-44d4-a22d-24d5e003f1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': 'True',\n",
       " 'delivery_days': '2',\n",
       " 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 獲取AI回應的dict \n",
    "output_dict = output_parser.parse(response.content)\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e393aa8-cee1-477c-b48c-1d91684114c2",
   "metadata": {},
   "source": [
    "## Memory\n",
    "以下展示對話的memory如何存取/提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "544df010-714e-4387-8c87-ba1a8ef503a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8f546f94-ad79-4b03-9152-49adc49cffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-4-1106-preview\")\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39a134a2-d821-43e0-aa5c-6b532694e86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi my name is Sean\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Sean! It's great to meet you. If there's anything specific you'd like to know or talk about, feel free to ask. I'm here to help with any questions you might have or to engage in a friendly chat on a topic of your choice.\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi my name is Sean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "867d1bd9-6602-4790-80c6-aa69f5ebe70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Sean\n",
      "AI: Hello Sean! It's great to meet you. If there's anything specific you'd like to know or talk about, feel free to ask. I'm here to help with any questions you might have or to engage in a friendly chat on a topic of your choice.\n",
      "Human: What is Large Language model?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A Large Language Model (LLM) like me is an advanced type of artificial intelligence that has been trained on a vast dataset of text. This training allows the model to understand and generate human-like text, enabling it to participate in conversations, answer questions, and even create content that can be surprisingly coherent and contextually relevant.\\n\\nThe \"large\" in Large Language Model refers to the number of parameters that the model uses. Parameters are essentially the aspects of the model that have been learned from the training data; they are the internal settings that determine how the model responds to a given input. Large Language Models can have billions or even hundreds of billions of parameters.\\n\\nOne of the most well-known examples of a Large Language Model is OpenAI\\'s GPT (Generative Pre-trained Transformer) series, with GPT-3 being a particularly famous iteration. These models are called transformers because of the type of neural network architecture they use, which is particularly good at handling sequences of data, like sentences in a text.\\n\\nLLMs are pre-trained on a diverse range of internet text, but they can also be fine-tuned on specific types of text or tasks to improve their performance in certain areas. They\\'re used in a variety of applications, from writing assistance and chatbots to more complex tasks like summarization, translation, and even coding.\\n\\nIt\\'s important to note that while LLMs can provide information that seems knowledgeable, they don\\'t \"understand\" content in the human sense and can sometimes generate incorrect or nonsensical responses. They also lack access to real-time data or personal experiences, so their knowledge is limited to what was available up to the point of their last training update.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is Large Language model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b839a3d0-2362-4891-acf4-e200c598cbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Sean\n",
      "AI: Hello Sean! It's great to meet you. If there's anything specific you'd like to know or talk about, feel free to ask. I'm here to help with any questions you might have or to engage in a friendly chat on a topic of your choice.\n",
      "Human: What is Large Language model?\n",
      "AI: A Large Language Model (LLM) like me is an advanced type of artificial intelligence that has been trained on a vast dataset of text. This training allows the model to understand and generate human-like text, enabling it to participate in conversations, answer questions, and even create content that can be surprisingly coherent and contextually relevant.\n",
      "\n",
      "The \"large\" in Large Language Model refers to the number of parameters that the model uses. Parameters are essentially the aspects of the model that have been learned from the training data; they are the internal settings that determine how the model responds to a given input. Large Language Models can have billions or even hundreds of billions of parameters.\n",
      "\n",
      "One of the most well-known examples of a Large Language Model is OpenAI's GPT (Generative Pre-trained Transformer) series, with GPT-3 being a particularly famous iteration. These models are called transformers because of the type of neural network architecture they use, which is particularly good at handling sequences of data, like sentences in a text.\n",
      "\n",
      "LLMs are pre-trained on a diverse range of internet text, but they can also be fine-tuned on specific types of text or tasks to improve their performance in certain areas. They're used in a variety of applications, from writing assistance and chatbots to more complex tasks like summarization, translation, and even coding.\n",
      "\n",
      "It's important to note that while LLMs can provide information that seems knowledgeable, they don't \"understand\" content in the human sense and can sometimes generate incorrect or nonsensical responses. They also lack access to real-time data or personal experiences, so their knowledge is limited to what was available up to the point of their last training update.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Sean, as you mentioned earlier. How can I assist you further today, Sean?'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "99e85f47-3205-48c3-baf6-aba2526cbbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Sean\n",
      "AI: Hello Sean! It's great to meet you. If there's anything specific you'd like to know or talk about, feel free to ask. I'm here to help with any questions you might have or to engage in a friendly chat on a topic of your choice.\n",
      "Human: What is Large Language model?\n",
      "AI: A Large Language Model (LLM) like me is an advanced type of artificial intelligence that has been trained on a vast dataset of text. This training allows the model to understand and generate human-like text, enabling it to participate in conversations, answer questions, and even create content that can be surprisingly coherent and contextually relevant.\n",
      "\n",
      "The \"large\" in Large Language Model refers to the number of parameters that the model uses. Parameters are essentially the aspects of the model that have been learned from the training data; they are the internal settings that determine how the model responds to a given input. Large Language Models can have billions or even hundreds of billions of parameters.\n",
      "\n",
      "One of the most well-known examples of a Large Language Model is OpenAI's GPT (Generative Pre-trained Transformer) series, with GPT-3 being a particularly famous iteration. These models are called transformers because of the type of neural network architecture they use, which is particularly good at handling sequences of data, like sentences in a text.\n",
      "\n",
      "LLMs are pre-trained on a diverse range of internet text, but they can also be fine-tuned on specific types of text or tasks to improve their performance in certain areas. They're used in a variety of applications, from writing assistance and chatbots to more complex tasks like summarization, translation, and even coding.\n",
      "\n",
      "It's important to note that while LLMs can provide information that seems knowledgeable, they don't \"understand\" content in the human sense and can sometimes generate incorrect or nonsensical responses. They also lack access to real-time data or personal experiences, so their knowledge is limited to what was available up to the point of their last training update.\n",
      "Human: What is my name?\n",
      "AI: Your name is Sean, as you mentioned earlier. How can I assist you further today, Sean?\n",
      "Human: summarize our conversation\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Certainly, Sean! We started our conversation with you introducing yourself by your name, Sean. I greeted you and offered to answer any questions or engage in a topic of your choice. You then asked about what a Large Language Model is, and I provided a detailed explanation, describing it as an AI trained on a vast dataset to generate human-like text, mentioning its large number of parameters, and giving examples like OpenAI's GPT series. I also noted the capabilities and limitations of LLMs. Lastly, you asked me to confirm your name, which I did, and now you've requested a summary of our conversation. Is there anything else you'd like to discuss or learn about?\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"summarize our conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7f7ca025-dd26-475d-bbc0-ef8a9d8028cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi my name is Sean\n",
      "AI: Hello Sean! It's great to meet you. If there's anything specific you'd like to know or talk about, feel free to ask. I'm here to help with any questions you might have or to engage in a friendly chat on a topic of your choice.\n",
      "Human: What is Large Language model?\n",
      "AI: A Large Language Model (LLM) like me is an advanced type of artificial intelligence that has been trained on a vast dataset of text. This training allows the model to understand and generate human-like text, enabling it to participate in conversations, answer questions, and even create content that can be surprisingly coherent and contextually relevant.\n",
      "\n",
      "The \"large\" in Large Language Model refers to the number of parameters that the model uses. Parameters are essentially the aspects of the model that have been learned from the training data; they are the internal settings that determine how the model responds to a given input. Large Language Models can have billions or even hundreds of billions of parameters.\n",
      "\n",
      "One of the most well-known examples of a Large Language Model is OpenAI's GPT (Generative Pre-trained Transformer) series, with GPT-3 being a particularly famous iteration. These models are called transformers because of the type of neural network architecture they use, which is particularly good at handling sequences of data, like sentences in a text.\n",
      "\n",
      "LLMs are pre-trained on a diverse range of internet text, but they can also be fine-tuned on specific types of text or tasks to improve their performance in certain areas. They're used in a variety of applications, from writing assistance and chatbots to more complex tasks like summarization, translation, and even coding.\n",
      "\n",
      "It's important to note that while LLMs can provide information that seems knowledgeable, they don't \"understand\" content in the human sense and can sometimes generate incorrect or nonsensical responses. They also lack access to real-time data or personal experiences, so their knowledge is limited to what was available up to the point of their last training update.\n",
      "Human: What is my name?\n",
      "AI: Your name is Sean, as you mentioned earlier. How can I assist you further today, Sean?\n",
      "Human: summarize our conversation\n",
      "AI: Certainly, Sean! We started our conversation with you introducing yourself by your name, Sean. I greeted you and offered to answer any questions or engage in a topic of your choice. You then asked about what a Large Language Model is, and I provided a detailed explanation, describing it as an AI trained on a vast dataset to generate human-like text, mentioning its large number of parameters, and giving examples like OpenAI's GPT series. I also noted the capabilities and limitations of LLMs. Lastly, you asked me to confirm your name, which I did, and now you've requested a summary of our conversation. Is there anything else you'd like to discuss or learn about?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cecb44bc-f962-411d-8642-9edc8e5f8b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Hi my name is Sean\\nAI: Hello Sean! It\\'s great to meet you. If there\\'s anything specific you\\'d like to know or talk about, feel free to ask. I\\'m here to help with any questions you might have or to engage in a friendly chat on a topic of your choice.\\nHuman: What is Large Language model?\\nAI: A Large Language Model (LLM) like me is an advanced type of artificial intelligence that has been trained on a vast dataset of text. This training allows the model to understand and generate human-like text, enabling it to participate in conversations, answer questions, and even create content that can be surprisingly coherent and contextually relevant.\\n\\nThe \"large\" in Large Language Model refers to the number of parameters that the model uses. Parameters are essentially the aspects of the model that have been learned from the training data; they are the internal settings that determine how the model responds to a given input. Large Language Models can have billions or even hundreds of billions of parameters.\\n\\nOne of the most well-known examples of a Large Language Model is OpenAI\\'s GPT (Generative Pre-trained Transformer) series, with GPT-3 being a particularly famous iteration. These models are called transformers because of the type of neural network architecture they use, which is particularly good at handling sequences of data, like sentences in a text.\\n\\nLLMs are pre-trained on a diverse range of internet text, but they can also be fine-tuned on specific types of text or tasks to improve their performance in certain areas. They\\'re used in a variety of applications, from writing assistance and chatbots to more complex tasks like summarization, translation, and even coding.\\n\\nIt\\'s important to note that while LLMs can provide information that seems knowledgeable, they don\\'t \"understand\" content in the human sense and can sometimes generate incorrect or nonsensical responses. They also lack access to real-time data or personal experiences, so their knowledge is limited to what was available up to the point of their last training update.\\nHuman: What is my name?\\nAI: Your name is Sean, as you mentioned earlier. How can I assist you further today, Sean?\\nHuman: summarize our conversation\\nAI: Certainly, Sean! We started our conversation with you introducing yourself by your name, Sean. I greeted you and offered to answer any questions or engage in a topic of your choice. You then asked about what a Large Language Model is, and I provided a detailed explanation, describing it as an AI trained on a vast dataset to generate human-like text, mentioning its large number of parameters, and giving examples like OpenAI\\'s GPT series. I also noted the capabilities and limitations of LLMs. Lastly, you asked me to confirm your name, which I did, and now you\\'ve requested a summary of our conversation. Is there anything else you\\'d like to discuss or learn about?'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取對話的內容\n",
    "mem_dict = memory.load_memory_variables({})\n",
    "mem_dict['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "14041cfb-7796-4d02-bd86-dd2a7608d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 或是有預設情境需要提取對話的內容\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": [\"Hi\", \"What's the weather?\"]}, \n",
    "                    {\"output\": [\"What's up\", \"It's nice day!\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "16b0a8af-2176-4616-a124-58fc6cc44e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ['Hi', \"What's the weather?\"]\n",
      "AI: [\"What's up\", \"It's nice day!\"]\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633fe888-1a7e-428e-a03b-700d2016bd91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
